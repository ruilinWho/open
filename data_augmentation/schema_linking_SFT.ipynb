{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from sql_metadata import Parser as SQLParser\n",
    "\n",
    "SPIDER_BASE = Path().cwd().parent / \"dataset\" / \"spider\"\n",
    "BIRD_TRAIN_BASE = Path().cwd().parent / \"dataset\" / \"bird-train\"\n",
    "BIRD_DEV_BASE = Path().cwd().parent / \"dataset\" / \"bird-dev\"\n",
    "\n",
    "TARGET = \"spider-train\"\n",
    "# TARGET = \"spider-dev\"\n",
    "# TARGET = \"bird-train\"\n",
    "# TARGET = \"bird-dev\"\n",
    "assert TARGET in [\"spider-train\", \"spider-dev\", \"bird-train\", \"bird-dev\"]\n",
    "\n",
    "if TARGET == \"spider-train\":\n",
    "    dataset_path1 = Path().cwd().parent / \"dataset\" / \"spider\" / \"train_spider.json\"\n",
    "    dataset_path2 = Path().cwd().parent / \"dataset\" / \"spider\" / \"train_others.json\"\n",
    "    train1 = json.load(open(dataset_path1))\n",
    "    train2 = json.load(open(dataset_path2))\n",
    "    dataset = train1 + train2\n",
    "    db_path = SPIDER_BASE / \"database\"\n",
    "else:\n",
    "    if TARGET == \"spider-dev\":\n",
    "        dataset_path = Path().cwd().parent / \"dataset\" / \"spider\" / \"dev.json\"\n",
    "        db_path = SPIDER_BASE / \"database\"\n",
    "    elif TARGET == \"bird-train\":\n",
    "        dataset_path = Path().cwd().parent / \"dataset\" / \"bird-train\" / \"train.json\"\n",
    "        db_path = BIRD_TRAIN_BASE / \"train_databases\"\n",
    "    elif TARGET == \"bird-dev\":\n",
    "        dataset_path = Path().cwd().parent / \"dataset\" / \"bird-dev\" / \"dev.json\"\n",
    "        db_path = BIRD_DEV_BASE / \"dev_databases\"\n",
    "    dataset = json.load(open(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gobegobe/NL2SQL-Project/dataset/spider/database\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_schema_dict = {}\n",
    "print(db_path)\n",
    "for db_dir in db_path.iterdir():\n",
    "    db_id = db_dir.stem\n",
    "    if db_id == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    ### Parse the DB\n",
    "    conn = sqlite3.connect(db_dir / f\"{db_id}.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    ### Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    table_names = [table[0] for table in tables]\n",
    "\n",
    "    schema = {}\n",
    "    ### For each table, get the columns\n",
    "    for idx, table_name in enumerate(table_names):\n",
    "        cursor.execute(f'PRAGMA table_info(\"{table_name}\")')\n",
    "        columns = cursor.fetchall()\n",
    "        columns_with_id = [(id, column[1].lower()) for id, column in enumerate(columns)]\n",
    "\n",
    "        schema[table_name.lower()] = {\"id\": idx, \"columns\": columns_with_id}\n",
    "\n",
    "    db_schema_dict[db_id] = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select name ,  age ,  country from artist order by year_join\n",
      "select name ,  age ,  country from artist order by year_join\n",
      "select name ,  year_join from artist where country != 'united states'\n",
      "select name ,  year_join from artist where country != 'united states'\n",
      "select count(*) from artist where age  >  46 and year_join  >  1990\n",
      "select count(*) from artist where age  >  46 and year_join  >  1990\n",
      "select name from artist order by year_join desc limit 1\n",
      "select name from artist order by year_join desc limit 1\n",
      "select join_year from pilot order by rank asc limit 1\n",
      "select t1.engineer_id ,  t1.first_name ,  t1.last_name from maintenance_engineers as t1 join engineer_visits as t2 group by t1.engineer_id order by count(*) desc limit 1\n",
      "select t1.name_first , t1.name_last from player as t1 join player_award as t2 where t2.year  =  1960 intersect select t1.name_first , t1.name_last from player as t1 join player_award as t2 where t2.year  =  1961\n",
      "select t1.name_first , t1.name_last from player as t1 join player_award as t2 where t2.year  =  1960 intersect select t1.name_first , t1.name_last from player as t1 join player_award as t2 where t2.year  =  1961\n",
      "select date_joined_staff from staff where first_name = \"janessa\" and last_name = \"sawayn\";\n",
      "select date_joined_staff from staff where first_name = \"janessa\" and last_name = \"sawayn\";\n"
     ]
    }
   ],
   "source": [
    "from sqlglot import parse_one, exp\n",
    "\n",
    "for datapoint in dataset:\n",
    "    if \"spider\" in TARGET:\n",
    "        original_query = datapoint[\"query\"]\n",
    "    else:\n",
    "        original_query = datapoint[\"SQL\"]\n",
    "\n",
    "    query = original_query.lower()\n",
    "    if \"is not ''\" in query:\n",
    "        query = query.replace(\"is not ''\", \"!= ''\")\n",
    "    if \"ref_company_types\" in query:\n",
    "        continue\n",
    "    if \"order details\" in query:\n",
    "        query = query.replace(\"order details\", \"orderdetails\")\n",
    "\n",
    "    # print(query)\n",
    "\n",
    "    schema = db_schema_dict[datapoint[\"db_id\"]]\n",
    "    # TODO\n",
    "    if \"join\" in query and \"on\" not in query:\n",
    "        print(query)\n",
    "\n",
    "    parsed = parse_one(query, dialect=\"sqlite\")\n",
    "\n",
    "    ### Get the tables and their aliases\n",
    "    appeared_table_with_columns = {}\n",
    "    alias_to_sql = {}\n",
    "    for table in parsed.find_all(exp.Table):\n",
    "        original_table_name = table.name.lower()\n",
    "        alias = table.alias\n",
    "\n",
    "        if original_table_name not in schema:\n",
    "            continue\n",
    "\n",
    "        if original_table_name not in appeared_table_with_columns:\n",
    "            appeared_table_with_columns[original_table_name] = []\n",
    "        if alias:\n",
    "            if alias not in alias_to_sql:\n",
    "                alias_to_sql[alias] = [original_table_name]\n",
    "            else:\n",
    "                alias_to_sql[alias].append(original_table_name)\n",
    "\n",
    "    if \"Show name of all students who have some friends and also are liked by someone else.\" in datapoint[\"question\"]:\n",
    "        print(alias_to_sql)\n",
    "\n",
    "    ### Get all the columns\n",
    "    for column in parsed.find_all(exp.Column):\n",
    "        ### Two different cases: table exists or not\n",
    "        if column.table:\n",
    "            ### Alias or table name\n",
    "\n",
    "            if column.table in alias_to_sql:\n",
    "                # table_name = alias_to_sql[column.table] if column.table in alias_to_sql else column.table\n",
    "                possible_tables = alias_to_sql[column.table]\n",
    "                for table_name in possible_tables:\n",
    "                    if table_name not in schema:\n",
    "                        continue\n",
    "\n",
    "                    column_names = [column[1] for column in schema[table_name][\"columns\"]]\n",
    "                    c_name = column.name.strip()\n",
    "                    if (c_name in column_names) and (c_name not in appeared_table_with_columns[table_name]):\n",
    "                        appeared_table_with_columns[table_name].append(c_name)\n",
    "\n",
    "            else:\n",
    "                c_name = column.name.strip()\n",
    "                if (column.table in appeared_table_with_columns) and (\n",
    "                    c_name not in appeared_table_with_columns[column.table]\n",
    "                ):\n",
    "                    appeared_table_with_columns[column.table].append(c_name)\n",
    "\n",
    "        else:\n",
    "            ### Search which table has the column\n",
    "            possible_tables = []\n",
    "            for table_name in appeared_table_with_columns.keys():\n",
    "                # XXX: This happens only when CTE is used\n",
    "                if table_name not in schema:\n",
    "                    continue\n",
    "\n",
    "                column_names = [column[1] for column in schema[table_name][\"columns\"]]\n",
    "                if column.name in column_names:\n",
    "                    possible_tables.append(table_name)\n",
    "\n",
    "            for table_name in possible_tables:\n",
    "                c_name = column.name.strip()\n",
    "                if c_name not in appeared_table_with_columns[table_name]:\n",
    "                    appeared_table_with_columns[table_name].append(c_name)\n",
    "\n",
    "    bad_dp = False\n",
    "    schema_link = {}\n",
    "    for table_name, columns in appeared_table_with_columns.items():\n",
    "        schema_link[table_name] = columns\n",
    "        if len(columns) == 0:\n",
    "            bad_dp = True\n",
    "\n",
    "    if bad_dp:\n",
    "        continue\n",
    "\n",
    "    answer_set.append(\n",
    "        {\n",
    "            \"db_id\": datapoint[\"db_id\"],\n",
    "            \"question\": datapoint[\"question\"],\n",
    "            \"gold_query\": original_query,\n",
    "            \"query\": query,\n",
    "            \"schema_link\": schema_link,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{TARGET}1.json\", \"w\") as f:\n",
    "    json.dump(answer_set, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3 quantity\n",
      "t1 unitprice\n",
      "t3 quantity\n",
      "t1 categoryid\n",
      "t2 categoryid\n",
      "t1 productid\n",
      "t3 productid\n",
      "t2 categoryname\n",
      "t3 quantity\n"
     ]
    }
   ],
   "source": [
    "sql0 = \"\"\"\n",
    "select count(t1.unitprice * t3.quantity) from products as t1 inner join categories as t2 on t1.categoryid = t2.categoryid inner join `order details` as t3 on t1.productid = t3.productid where t2.categoryname = 'confections' group by t3.quantity order by t3.quantity desc limit 1\"\"\"\n",
    "parsed = parse_one(sql0, dialect=\"sqlite\")\n",
    "\n",
    "for column in parsed.find_all(exp.Column):\n",
    "    print(column.table, column.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
